# @package _global_

env:
  name: dmc_cheetah_run
  demo: cheetah_run_10.pkl #TODO: 50 expert trajectories

  # learn_steps: 1e5
  # eval_interval: 1e3

  replay_mem: 1e6
  # initial_mem: 10000

  eps_steps: 100000
  eps_window: 10
  learn_steps: 1e6
  eval_interval: 5e3

expert:
  demos: 1
  subsample_freq: 1

eval:
  policy: 
  threshold: 5000

agent:
  name: sac

log_interval: 500  # Log every this many steps
num_actor_updates: 1

train:
  use_target: true
  soft_update: true
  batch: 256

q_net:
  _target_: agent.sac_models.SingleQCritic
